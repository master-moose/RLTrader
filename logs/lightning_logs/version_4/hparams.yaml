attention: true
bidirectional: true
class_weights: null
dropout: 0.5
embedding_dim: null
focal_gamma: 2.0
hidden_dims: 128
input_dims:
  15m: 34
  1d: 34
  4h: 34
learning_rate: 0.0003
lr_scheduler_factor: 0.5
lr_scheduler_patience: 10
mixup_alpha: 0.2
num_classes: 3
num_layers: 2
use_batch_norm: true
use_focal_loss: true
use_residual: true
warm_up_steps: 100
weight_decay: 0.001
