{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"c97f7bdd\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bf020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c097361635f66696e616c948c0e747269616c5f6469725f6e616d65948c1c747269616c5f526d625736525f6c72312e39652d30355f6273323536948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c2a433a2f55736572732f757365722f4465736b746f702f6c74736d2d64716e2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819681f68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d30342d32365f32312d34362d30329475622e\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_sac\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"drawdown_penalty_weight\": 0.18744555510050076,\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"idle_penalty_weight\": 0.00616639394123415,\n    \"profit_bonus_weight\": 0.5401344508941235,\n    \"exploration_bonus_weight\": 0.0,\n    \"trade_penalty_weight\": 0.037584408790909976,\n    \"n_epochs\": 10,\n    \"clip_range\": 0.1,\n    \"vf_coef\": 0.5,\n    \"ent_coef\": 0.024322430048846218,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 64,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"gae_lambda\": 0.95,\n    \"max_grad_norm\": 0.5,\n    \"norm_obs\": \"auto\",\n    \"gradient_steps\": 1,\n    \"total_timesteps\": 200000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 2,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_fp16.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_fp16.h5\",\n    \"exp_name\": \"sac_final\",\n    \"num_samples\": 20,\n    \"cpus_per_trial\": 4.0,\n    \"gpus_per_trial\": 1.0,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 200000,\n    \"num_envs\": 1,\n    \"cpu_only\": false,\n    \"learning_rate\": 1.888091309771574e-05,\n    \"gamma\": 0.995,\n    \"portfolio_change_weight\": 4.234719274673099,\n    \"buffer_size\": 100000,\n    \"batch_size\": 256,\n    \"tau\": 0.006350550589311369,\n    \"learning_starts\": 1000\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_sac\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"drawdown_penalty_weight\": 0.18744555510050076,\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"idle_penalty_weight\": 0.00616639394123415,\n    \"profit_bonus_weight\": 0.5401344508941235,\n    \"exploration_bonus_weight\": 0.0,\n    \"trade_penalty_weight\": 0.037584408790909976,\n    \"n_epochs\": 10,\n    \"clip_range\": 0.1,\n    \"vf_coef\": 0.5,\n    \"ent_coef\": 0.024322430048846218,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 64,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"gae_lambda\": 0.95,\n    \"max_grad_norm\": 0.5,\n    \"norm_obs\": \"auto\",\n    \"gradient_steps\": 1,\n    \"total_timesteps\": 200000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 2,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_fp16.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_fp16.h5\",\n    \"exp_name\": \"sac_final\",\n    \"num_samples\": 20,\n    \"cpus_per_trial\": 4.0,\n    \"gpus_per_trial\": 1.0,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 200000,\n    \"num_envs\": 1,\n    \"cpu_only\": false,\n    \"learning_rate\": 1.888091309771574e-05,\n    \"gamma\": 0.995,\n    \"portfolio_change_weight\": 4.234719274673099,\n    \"buffer_size\": 100000,\n    \"batch_size\": 256,\n    \"tau\": 0.006350550589311369,\n    \"learning_starts\": 1000\n  },\n  \"evaluated_params\": {\n    \"drawdown_penalty_weight\": 0.18744555510050076,\n    \"idle_penalty_weight\": 0.00616639394123415,\n    \"profit_bonus_weight\": 0.5401344508941235,\n    \"trade_penalty_weight\": 0.037584408790909976,\n    \"ent_coef\": 0.024322430048846218,\n    \"learning_rate\": 1.888091309771574e-05,\n    \"gamma\": 0.995,\n    \"portfolio_change_weight\": 4.234719274673099,\n    \"buffer_size\": 100000,\n    \"batch_size\": 256,\n    \"tau\": 0.006350550589311369,\n    \"learning_starts\": 1000\n  },\n  \"experiment_tag\": \"1_batch_size=256,benchmark_reward_weight=0.0000,buffer_size=100000,clip_range=0.1000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=4.0000,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_fp16_h5,drawdown_penalty_weight=0.1874,ent_coef=0.0243,eval_freq=10000,exp_name=sac_final,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9500,gamma=0.9950,gpus_per_trial=1.0000,gradient_steps=1,idle_penalty_weight=0.0062,initial_balance=10000.0000,learning_rate=0.0000,learning_starts=1000,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=0.5000,max_steps=20000,model_type=tcn_sac,n_epochs=10,n_eval_episodes=3,n_lstm_layers=2,norm_obs=auto,num_envs=1,num_samples=20,portfolio_change_weight=4.2347,profit_bonus_weight=0.5401,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=64,shared_lstm=shared,sharpe_reward_weight=0.0000,tau=0.0064,timesteps_per_trial=200000,total_timesteps=200000,trade_penalty_weight=0.0376,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_fp16_h5,verbose=2,vf_coef=0.5000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"relative_logdir\": \"trial_RmbW6R_lr1.9e-05_bs256\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_RmbW6R_lr1.9e-05_bs256\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745696769.4661703,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"resources_memory_mb\": 9632.59375,\n    \"resources_cpu_percent\": 53.1,\n    \"train/learning_rate\": 1.878603650939972e-05,\n    \"train/n_updates\": 5.0,\n    \"train/ent_coef\": 0.024322429671883583,\n    \"train/actor_loss\": 0.026495780795812607,\n    \"train/critic_loss\": 1.1472762823104858,\n    \"rollout/ep_rew_mean\": 0.0,\n    \"rollout/ep_len_mean\": 0,\n    \"rollout/fps\": 34,\n    \"time/total_timesteps\": 1006,\n    \"combined_score\": 0.2025155596063114,\n    \"timestamp\": 1745696805,\n    \"checkpoint_dir_name\": null,\n    \"done\": false,\n    \"training_iteration\": 1106,\n    \"trial_id\": \"c97f7bdd\",\n    \"date\": \"2025-04-26_21-46-45\",\n    \"time_this_iter_s\": 4.159202814102173,\n    \"time_total_s\": 32.26831889152527,\n    \"pid\": 36472,\n    \"hostname\": \"WINDOWS-6KA6PMF\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"model_type\": \"tcn_sac\",\n      \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n      \"drawdown_penalty_weight\": 0.18744555510050076,\n      \"sharpe_reward_weight\": 0.0,\n      \"fee_penalty_weight\": 0.0,\n      \"benchmark_reward_weight\": 0.0,\n      \"consistency_penalty_weight\": 0.0,\n      \"idle_penalty_weight\": 0.00616639394123415,\n      \"profit_bonus_weight\": 0.5401344508941235,\n      \"exploration_bonus_weight\": 0.0,\n      \"trade_penalty_weight\": 0.037584408790909976,\n      \"n_epochs\": 10,\n      \"clip_range\": 0.1,\n      \"vf_coef\": 0.5,\n      \"ent_coef\": 0.024322430048846218,\n      \"lstm_hidden_size\": 256,\n      \"n_lstm_layers\": 2,\n      \"shared_lstm\": \"shared\",\n      \"sequence_length\": 64,\n      \"max_steps\": 20000,\n      \"initial_balance\": 10000.0,\n      \"commission\": 0.0,\n      \"reward_scaling\": 1.0,\n      \"gae_lambda\": 0.95,\n      \"max_grad_norm\": 0.5,\n      \"norm_obs\": \"auto\",\n      \"gradient_steps\": 1,\n      \"total_timesteps\": 200000,\n      \"eval_freq\": 10000,\n      \"n_eval_episodes\": 3,\n      \"save_freq\": 50000,\n      \"verbose\": 2,\n      \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_fp16.h5\",\n      \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_fp16.h5\",\n      \"exp_name\": \"sac_final\",\n      \"num_samples\": 20,\n      \"cpus_per_trial\": 4.0,\n      \"gpus_per_trial\": 1.0,\n      \"search_algo\": \"optuna\",\n      \"local_dir\": \"./ray_results\",\n      \"timesteps_per_trial\": 200000,\n      \"num_envs\": 1,\n      \"cpu_only\": false,\n      \"learning_rate\": 1.888091309771574e-05,\n      \"gamma\": 0.995,\n      \"portfolio_change_weight\": 4.234719274673099,\n      \"buffer_size\": 100000,\n      \"batch_size\": 256,\n      \"tau\": 0.006350550589311369,\n      \"learning_starts\": 1000\n    },\n    \"time_since_restore\": 32.26831889152527,\n    \"iterations_since_restore\": 1106,\n    \"experiment_tag\": \"1_batch_size=256,benchmark_reward_weight=0.0000,buffer_size=100000,clip_range=0.1000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=4.0000,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_fp16_h5,drawdown_penalty_weight=0.1874,ent_coef=0.0243,eval_freq=10000,exp_name=sac_final,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9500,gamma=0.9950,gpus_per_trial=1.0000,gradient_steps=1,idle_penalty_weight=0.0062,initial_balance=10000.0000,learning_rate=0.0000,learning_starts=1000,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=0.5000,max_steps=20000,model_type=tcn_sac,n_epochs=10,n_eval_episodes=3,n_lstm_layers=2,norm_obs=auto,num_envs=1,num_samples=20,portfolio_change_weight=4.2347,profit_bonus_weight=0.5401,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=64,shared_lstm=shared,sharpe_reward_weight=0.0000,tau=0.0064,timesteps_per_trial=200000,total_timesteps=200000,trade_penalty_weight=0.0376,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_fp16_h5,verbose=2,vf_coef=0.5000\"\n  },\n  \"last_result_time\": 1745696805.3048897,\n  \"metric_analysis\": {\n    \"rollout/ep_rew_mean\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"rollout/ep_len_mean\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"rollout/fps\": {\n      \"max\": 281,\n      \"min\": 34,\n      \"avg\": 132.53991269885702,\n      \"last\": 34,\n      \"last-5-avg\": 50.6,\n      \"last-10-avg\": 88.4\n    },\n    \"time/total_timesteps\": {\n      \"max\": 1006,\n      \"min\": 1,\n      \"avg\": 479.7379607735381,\n      \"last\": 1006,\n      \"last-5-avg\": 1004.0,\n      \"last-10-avg\": 1001.5\n    },\n    \"combined_score\": {\n      \"max\": 0.20915612438229286,\n      \"min\": 0.175,\n      \"avg\": 0.17513689488514475,\n      \"last\": 0.2025155596063114,\n      \"last-5-avg\": 0.2052811485934857,\n      \"last-10-avg\": 0.19014057429674286\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 1106,\n      \"min\": 1,\n      \"avg\": 553.5000000000005,\n      \"last\": 1106,\n      \"last-5-avg\": 1104.0,\n      \"last-10-avg\": 1101.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 6.291384696960449,\n      \"min\": 0.0,\n      \"avg\": 0.029175695200294068,\n      \"last\": 4.159202814102173,\n      \"last-5-avg\": 4.203841638565064,\n      \"last-10-avg\": 2.1799579858779907\n    },\n    \"time_total_s\": {\n      \"max\": 32.26831889152527,\n      \"min\": 6.291384696960449,\n      \"avg\": 8.35357641893527,\n      \"last\": 32.26831889152527,\n      \"last-5-avg\": 24.05598635673523,\n      \"last-10-avg\": 17.37076802253723\n    },\n    \"time_since_restore\": {\n      \"max\": 32.26831889152527,\n      \"min\": 6.291384696960449,\n      \"avg\": 8.35357641893527,\n      \"last\": 32.26831889152527,\n      \"last-5-avg\": 24.05598635673523,\n      \"last-10-avg\": 17.37076802253723\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1106,\n      \"min\": 1,\n      \"avg\": 553.5000000000005,\n      \"last\": 1106,\n      \"last-5-avg\": 1104.0,\n      \"last-10-avg\": 1101.5\n    },\n    \"timesteps_total\": {\n      \"max\": 1000,\n      \"min\": 10,\n      \"avg\": 90.08341807627659,\n      \"last\": 1000,\n      \"last-5-avg\": 980.0,\n      \"last-10-avg\": 955.0\n    },\n    \"fps\": {\n      \"max\": 137,\n      \"min\": 124,\n      \"avg\": 127.29580062044032,\n      \"last\": 127,\n      \"last-5-avg\": 129.4,\n      \"last-10-avg\": 130.1\n    },\n    \"resources_memory_mb\": {\n      \"max\": 9632.59375,\n      \"min\": 9632.59375,\n      \"avg\": 9632.59375,\n      \"last\": 9632.59375,\n      \"last-5-avg\": 9632.59375,\n      \"last-10-avg\": 9632.59375\n    },\n    \"resources_cpu_percent\": {\n      \"max\": 53.1,\n      \"min\": 53.1,\n      \"avg\": 53.09999999999998,\n      \"last\": 53.1,\n      \"last-5-avg\": 53.1,\n      \"last-10-avg\": 53.10000000000001\n    },\n    \"train/learning_rate\": {\n      \"max\": 1.878641412766167e-05,\n      \"min\": 1.878603650939972e-05,\n      \"avg\": 1.878641327409417e-05,\n      \"last\": 1.878603650939972e-05,\n      \"last-5-avg\": 1.8786225318530695e-05,\n      \"last-10-avg\": 1.8786225318530695e-05\n    },\n    \"train/n_updates\": {\n      \"max\": 5.0,\n      \"min\": 1.0,\n      \"avg\": 1.0090415913200723,\n      \"last\": 5.0,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"train/ent_coef\": {\n      \"max\": 0.024322429671883583,\n      \"min\": 0.024322429671883583,\n      \"avg\": 0.024322429671883583,\n      \"last\": 0.024322429671883583,\n      \"last-5-avg\": 0.024322429671883583,\n      \"last-10-avg\": 0.024322429671883583\n    },\n    \"train/actor_loss\": {\n      \"max\": 0.040773436427116394,\n      \"min\": 0.026495780795812607,\n      \"avg\": 0.04074905392382072,\n      \"last\": 0.026495780795812607,\n      \"last-5-avg\": 0.035380026698112486,\n      \"last-10-avg\": 0.035380026698112486\n    },\n    \"train/critic_loss\": {\n      \"max\": 1.1480653285980225,\n      \"min\": 0.7039355039596558,\n      \"avg\": 0.7050635630355822,\n      \"last\": 1.1472762823104858,\n      \"last-5-avg\": 0.9534621715545655,\n      \"last-10-avg\": 0.9534621715545655\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"rollout/ep_rew_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000470000000000000000652e\"\n      }\n    },\n    \"rollout/ep_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"rollout/fps\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b4b4b3a4b2f4b274b22652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b814b814b814b7f4b754b4b4b3a4b2f4b274b22652e\"\n      }\n    },\n    \"time/total_timesteps\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dea034deb034dec034ded034dee03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284de5034de6034de7034de8034de9034dea034deb034dec034ded034dee03652e\"\n      }\n    },\n    \"combined_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fcac5a0bcfd727a473fca4e933bdcfbd4473fca79ec64713e7e473fc9e71b6b385974473fc9ec07a4b859fc652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fc6666666666666473fc6666666666666473fc6666666666666473fc6666666666666473fc6666666666666473fcac5a0bcfd727a473fca4e933bdcfbd4473fca79ec64713e7e473fc9e71b6b385974473fc9ec07a4b859fc652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d4e044d4f044d50044d51044d5204652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d49044d4a044d4b044d4c044d4d044d4e044d4f044d50044d51044d5204652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474012add6a000000047401028363000000047401044f34000000047401055a530000000474010a30610000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f8f268000000000473f72b04000000000473fbd54e400000000470000000000000000473fe4ac3700000000474012add6a000000047401028363000000047401044f34000000047401055a530000000474010a30610000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402fd676c0000000474033f548ec0000004740380685bc00000047403c1bef08000000474040225846000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474024f7c830000000474024fa1e3800000047402534c80000000047402534c8000000004740267f8b7000000047402fd676c0000000474033f548ec0000004740380685bc00000047403c1bef08000000474040225846000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402fd676c0000000474033f548ec0000004740380685bc00000047403c1bef08000000474040225846000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474024f7c830000000474024fa1e3800000047402534c80000000047402534c8000000004740267f8b7000000047402fd676c0000000474033f548ec0000004740380685bc00000047403c1bef08000000474040225846000000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d4e044d4f044d50044d51044d5204652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d49044d4a044d4b044d4c044d4d044d4e044d4f044d50044d51044d5204652e\"\n      }\n    },\n    \"timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dc0034dca034dd4034dde034de803652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d8e034d98034da2034dac034db6034dc0034dca034dd4034dde034de803652e\"\n      }\n    },\n    \"fps\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b824b824b824b824b7f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b834b834b834b834b824b824b824b824b824b7f652e\"\n      }\n    },\n    \"resources_memory_mb\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c2d04c000000004740c2d04c000000004740c2d04c000000004740c2d04c000000004740c2d04c00000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059561000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c2d04c000000004740c2d04c000000004740c2d04c000000004740c2d04c000000004740c2d04c000000004740c2d04c000000004740c2d04c00000000652e\"\n      }\n    },\n    \"resources_cpu_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a8ccccccccccd47404a8ccccccccccd47404a8ccccccccccd47404a8ccccccccccd47404a8ccccccccccd652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059561000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a8ccccccccccd47404a8ccccccccccd47404a8ccccccccccd47404a8ccccccccccd47404a8ccccccccccd47404a8ccccccccccd47404a8ccccccccccd652e\"\n      }\n    },\n    \"train/learning_rate\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ef3b2f08c70f705473ef3b2ea0fa89957473ef3b2e392e03ba7473ef3b2dd1617ddf8473ef3b2d6994f8049652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ef3b2f08c70f705473ef3b2ea0fa89957473ef3b2e392e03ba7473ef3b2dd1617ddf8473ef3b2d6994f8049652e\"\n      }\n    },\n    \"train/n_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473ff0000000000000474000000000000000474008000000000000474010000000000000474014000000000000652e\"\n      }\n    },\n    \"train/ent_coef\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f98e7faa0000000473f98e7faa0000000473f98e7faa0000000473f98e7faa0000000473f98e7faa0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f98e7faa0000000473f98e7faa0000000473f98e7faa0000000473f98e7faa0000000473f98e7faa0000000652e\"\n      }\n    },\n    \"train/actor_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fa4e04180000000473fa438b940000000473fa373d140000000473fa07500a0000000473f9b21b5c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fa4e04180000000473fa438b940000000473fa373d140000000473fa07500a0000000473f9b21b5c0000000652e\"\n      }\n    },\n    \"train/critic_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe686a3c0000000473fed91aac0000000473feb0210c0000000473ff25e79c0000000473ff25b3e60000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe686a3c0000000473fed91aac0000000473feb0210c0000000473ff25e79c0000000473ff25b3e60000000652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"dd2b7409\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595c7030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c097361635f66696e616c948c0e747269616c5f6469725f6e616d65948c1d747269616c5f6e53746976685f6c72312e37652d30345f627331303234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c2a433a2f55736572732f757365722f4465736b746f702f6c74736d2d64716e2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819681f68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d649468008c125f75706c6f61645f746f5f66735f706174689493947d94288c0a6c6f63616c5f70617468948c86433a2f55736572732f757365722f417070446174612f4c6f63616c2f54656d702f7261792f73657373696f6e5f323032352d30342d32365f32312d34352d35395f3534393234325f33363636382f6172746966616374732f323032352d30342d32365f32312d34362d30322f7361635f66696e616c2f6472697665725f617274696661637473948c02667394681f8c0766735f70617468948c34433a2f55736572732f757365722f4465736b746f702f6c74736d2d64716e2f7261795f726573756c74732f7361635f66696e616c948c076578636c756465944e75869475628c0a5f74696d657374616d70948c13323032352d30342d32365f32312d34362d30329475622e\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_sac\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"drawdown_penalty_weight\": 0.10218070642581208,\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"idle_penalty_weight\": 0.04884637045874056,\n    \"profit_bonus_weight\": 0.8517259631592308,\n    \"exploration_bonus_weight\": 0.0,\n    \"trade_penalty_weight\": 0.08042299669979114,\n    \"n_epochs\": 10,\n    \"clip_range\": 0.1,\n    \"vf_coef\": 0.5,\n    \"ent_coef\": 0.006083034718362299,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 64,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"gae_lambda\": 0.95,\n    \"max_grad_norm\": 0.5,\n    \"norm_obs\": \"auto\",\n    \"gradient_steps\": 1,\n    \"total_timesteps\": 200000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 2,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_fp16.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_fp16.h5\",\n    \"exp_name\": \"sac_final\",\n    \"num_samples\": 20,\n    \"cpus_per_trial\": 4.0,\n    \"gpus_per_trial\": 1.0,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 200000,\n    \"num_envs\": 1,\n    \"cpu_only\": false,\n    \"learning_rate\": 0.00017082515008416912,\n    \"gamma\": 0.995,\n    \"portfolio_change_weight\": 4.309019415886809,\n    \"buffer_size\": 500000,\n    \"batch_size\": 1024,\n    \"tau\": 0.011101460111946446,\n    \"learning_starts\": 10000\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_sac\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"drawdown_penalty_weight\": 0.10218070642581208,\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"idle_penalty_weight\": 0.04884637045874056,\n    \"profit_bonus_weight\": 0.8517259631592308,\n    \"exploration_bonus_weight\": 0.0,\n    \"trade_penalty_weight\": 0.08042299669979114,\n    \"n_epochs\": 10,\n    \"clip_range\": 0.1,\n    \"vf_coef\": 0.5,\n    \"ent_coef\": 0.006083034718362299,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 64,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"gae_lambda\": 0.95,\n    \"max_grad_norm\": 0.5,\n    \"norm_obs\": \"auto\",\n    \"gradient_steps\": 1,\n    \"total_timesteps\": 200000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 2,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_fp16.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_fp16.h5\",\n    \"exp_name\": \"sac_final\",\n    \"num_samples\": 20,\n    \"cpus_per_trial\": 4.0,\n    \"gpus_per_trial\": 1.0,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 200000,\n    \"num_envs\": 1,\n    \"cpu_only\": false,\n    \"learning_rate\": 0.00017082515008416912,\n    \"gamma\": 0.995,\n    \"portfolio_change_weight\": 4.309019415886809,\n    \"buffer_size\": 500000,\n    \"batch_size\": 1024,\n    \"tau\": 0.011101460111946446,\n    \"learning_starts\": 10000\n  },\n  \"evaluated_params\": {\n    \"drawdown_penalty_weight\": 0.10218070642581208,\n    \"idle_penalty_weight\": 0.04884637045874056,\n    \"profit_bonus_weight\": 0.8517259631592308,\n    \"trade_penalty_weight\": 0.08042299669979114,\n    \"ent_coef\": 0.006083034718362299,\n    \"learning_rate\": 0.00017082515008416912,\n    \"gamma\": 0.995,\n    \"portfolio_change_weight\": 4.309019415886809,\n    \"buffer_size\": 500000,\n    \"batch_size\": 1024,\n    \"tau\": 0.011101460111946446,\n    \"learning_starts\": 10000\n  },\n  \"experiment_tag\": \"2_batch_size=1024,benchmark_reward_weight=0.0000,buffer_size=500000,clip_range=0.1000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=4.0000,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_fp16_h5,drawdown_penalty_weight=0.1022,ent_coef=0.0061,eval_freq=10000,exp_name=sac_final,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9500,gamma=0.9950,gpus_per_trial=1.0000,gradient_steps=1,idle_penalty_weight=0.0488,initial_balance=10000.0000,learning_rate=0.0002,learning_starts=10000,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=0.5000,max_steps=20000,model_type=tcn_sac,n_epochs=10,n_eval_episodes=3,n_lstm_layers=2,norm_obs=auto,num_envs=1,num_samples=20,portfolio_change_weight=4.3090,profit_bonus_weight=0.8517,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=64,shared_lstm=shared,sharpe_reward_weight=0.0000,tau=0.0111,timesteps_per_trial=200000,total_timesteps=200000,trade_penalty_weight=0.0804,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_fp16_h5,verbose=2,vf_coef=0.5000\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740100000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"relative_logdir\": \"trial_nStivh_lr1.7e-04_bs1024\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_nStivh_lr1.7e-04_bs1024\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": null,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": Infinity, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 1, "_metric": null, "_total_time": 32.26831889152527, "_iteration": 1452, "_has_errored": false, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1745696762.4125493, "_session_str": "2025-04-26_21-46-02", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f3000000000000008c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1745696762.4125493}}