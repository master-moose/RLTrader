{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"7a6539cf\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595c8020000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1174636e5f70706f5f686f6d657377656570948c0e747269616c5f6469725f6e616d65948c1d747269616c5f5a3645524c545f6c72372e39652d30355f6e7334303936948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c2a433a2f55736572732f757365722f4465736b746f702f6c74736d2d64716e2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819681f68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032352d30342d32355f31312d31392d30349475622e\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 7.936347908683988e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.005443048161550511,\n    \"vf_coef\": 0.6944424213296199,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.9,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 5.154906548226789,\n    \"drawdown_penalty_weight\": 0.036485428222695446,\n    \"idle_penalty_weight\": 0.028359375737115628,\n    \"profit_bonus_weight\": 0.6391989655936917,\n    \"trade_penalty_weight\": 0.05824367079613203\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 7.936347908683988e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.005443048161550511,\n    \"vf_coef\": 0.6944424213296199,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.9,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 5.154906548226789,\n    \"drawdown_penalty_weight\": 0.036485428222695446,\n    \"idle_penalty_weight\": 0.028359375737115628,\n    \"profit_bonus_weight\": 0.6391989655936917,\n    \"trade_penalty_weight\": 0.05824367079613203\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 7.936347908683988e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.005443048161550511,\n    \"vf_coef\": 0.6944424213296199,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.9,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 5.154906548226789,\n    \"drawdown_penalty_weight\": 0.036485428222695446,\n    \"idle_penalty_weight\": 0.028359375737115628,\n    \"profit_bonus_weight\": 0.6391989655936917,\n    \"trade_penalty_weight\": 0.05824367079613203\n  },\n  \"experiment_tag\": \"1_base_config=None,benchmark_reward_weight=0.0000,clip_range=0.2000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=2.0000,data_key=None,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_data_normalized_h5,drawdown_penalty_weight=0.0365,ent_coef=0.0054,eval_freq=10000,exp_name=tcn_ppo_homesweep,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9000,gamma=0.9900,gpus_per_trial=0.5000,idle_penalty_weight=0.0284,initial_balance=10000.0000,learning_rate=0.0001,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=0.5000,max_steps=20000,model_type=tcn_ppo,n_epochs=5,n_eval_episodes=3,n_lstm_layers=2,n_steps=4096,norm_obs=auto,num_envs=2,num_samples=10,portfolio_change_weight=5.1549,profit_bonus_weight=0.6392,ray_address=None,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=96,shared_lstm=shared,sharpe_reward_weight=0.0000,timesteps_per_trial=500000,total_timesteps=500000,trade_penalty_weight=0.0582,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_data_normalized_h5,verbose=1,vf_coef=0.6944\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"trial_Z6ERLT_lr7.9e-05_ns4096\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_Z6ERLT_lr7.9e-05_ns4096\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745572751.1568663,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {\n    \"trial_id\": \"7a6539cf\"\n  },\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"8e1ab76f\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 0.00016014805929547333,\n    \"gamma\": 0.99,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.02936132738801508,\n    \"vf_coef\": 0.8019874389371497,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 3.7024447947710017,\n    \"drawdown_penalty_weight\": 0.19320238081313507,\n    \"idle_penalty_weight\": 0.030061633917122563,\n    \"profit_bonus_weight\": 1.3118131768749262,\n    \"trade_penalty_weight\": 0.023396426720792108\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 0.00016014805929547333,\n    \"gamma\": 0.99,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.02936132738801508,\n    \"vf_coef\": 0.8019874389371497,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 3.7024447947710017,\n    \"drawdown_penalty_weight\": 0.19320238081313507,\n    \"idle_penalty_weight\": 0.030061633917122563,\n    \"profit_bonus_weight\": 1.3118131768749262,\n    \"trade_penalty_weight\": 0.023396426720792108\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00016014805929547333,\n    \"gamma\": 0.99,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.02936132738801508,\n    \"vf_coef\": 0.8019874389371497,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 3.7024447947710017,\n    \"drawdown_penalty_weight\": 0.19320238081313507,\n    \"idle_penalty_weight\": 0.030061633917122563,\n    \"profit_bonus_weight\": 1.3118131768749262,\n    \"trade_penalty_weight\": 0.023396426720792108\n  },\n  \"experiment_tag\": \"2_base_config=None,benchmark_reward_weight=0.0000,clip_range=0.2000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=2.0000,data_key=None,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_data_normalized_h5,drawdown_penalty_weight=0.1932,ent_coef=0.0294,eval_freq=10000,exp_name=tcn_ppo_homesweep,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9500,gamma=0.9900,gpus_per_trial=0.5000,idle_penalty_weight=0.0301,initial_balance=10000.0000,learning_rate=0.0002,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=1.0000,max_steps=20000,model_type=tcn_ppo,n_epochs=3,n_eval_episodes=3,n_lstm_layers=2,n_steps=4096,norm_obs=auto,num_envs=2,num_samples=10,portfolio_change_weight=3.7024,profit_bonus_weight=1.3118,ray_address=None,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=96,shared_lstm=shared,sharpe_reward_weight=0.0000,timesteps_per_trial=500000,total_timesteps=500000,trade_penalty_weight=0.0234,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_data_normalized_h5,verbose=1,vf_coef=0.8020\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"trial_C9UCrC_lr1.6e-04_ns4096\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_C9UCrC_lr1.6e-04_ns4096\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745572757.7850623,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"64dcf1d4\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 0.0003218295730361665,\n    \"gamma\": 0.995,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.06108277600795938,\n    \"vf_coef\": 0.7006771386931312,\n    \"clip_range\": 0.1,\n    \"gae_lambda\": 0.98,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 1.450627612167776,\n    \"drawdown_penalty_weight\": 0.05954682061083336,\n    \"idle_penalty_weight\": 0.03082193161248899,\n    \"profit_bonus_weight\": 1.1496254697429753,\n    \"trade_penalty_weight\": 0.0807207678492965\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 0.0003218295730361665,\n    \"gamma\": 0.995,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.06108277600795938,\n    \"vf_coef\": 0.7006771386931312,\n    \"clip_range\": 0.1,\n    \"gae_lambda\": 0.98,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 1.450627612167776,\n    \"drawdown_penalty_weight\": 0.05954682061083336,\n    \"idle_penalty_weight\": 0.03082193161248899,\n    \"profit_bonus_weight\": 1.1496254697429753,\n    \"trade_penalty_weight\": 0.0807207678492965\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.0003218295730361665,\n    \"gamma\": 0.995,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.06108277600795938,\n    \"vf_coef\": 0.7006771386931312,\n    \"clip_range\": 0.1,\n    \"gae_lambda\": 0.98,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 1.450627612167776,\n    \"drawdown_penalty_weight\": 0.05954682061083336,\n    \"idle_penalty_weight\": 0.03082193161248899,\n    \"profit_bonus_weight\": 1.1496254697429753,\n    \"trade_penalty_weight\": 0.0807207678492965\n  },\n  \"experiment_tag\": \"3_base_config=None,benchmark_reward_weight=0.0000,clip_range=0.1000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=2.0000,data_key=None,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_data_normalized_h5,drawdown_penalty_weight=0.0595,ent_coef=0.0611,eval_freq=10000,exp_name=tcn_ppo_homesweep,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9800,gamma=0.9950,gpus_per_trial=0.5000,idle_penalty_weight=0.0308,initial_balance=10000.0000,learning_rate=0.0003,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=0.5000,max_steps=20000,model_type=tcn_ppo,n_epochs=3,n_eval_episodes=3,n_lstm_layers=2,n_steps=4096,norm_obs=auto,num_envs=2,num_samples=10,portfolio_change_weight=1.4506,profit_bonus_weight=1.1496,ray_address=None,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=96,shared_lstm=shared,sharpe_reward_weight=0.0000,timesteps_per_trial=500000,total_timesteps=500000,trade_penalty_weight=0.0807,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_data_normalized_h5,verbose=1,vf_coef=0.7007\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"trial_8NV6gU_lr3.2e-04_ns4096\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_8NV6gU_lr3.2e-04_ns4096\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745572767.801345,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"08e4b439\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 5.093997149645848e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.03883558523405716,\n    \"vf_coef\": 0.6092246418885853,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 6.825744777753561,\n    \"drawdown_penalty_weight\": 0.15576397647256385,\n    \"idle_penalty_weight\": 0.04271573174573301,\n    \"profit_bonus_weight\": 0.8270967268473195,\n    \"trade_penalty_weight\": 0.0602221376631763\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 5.093997149645848e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.03883558523405716,\n    \"vf_coef\": 0.6092246418885853,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 6.825744777753561,\n    \"drawdown_penalty_weight\": 0.15576397647256385,\n    \"idle_penalty_weight\": 0.04271573174573301,\n    \"profit_bonus_weight\": 0.8270967268473195,\n    \"trade_penalty_weight\": 0.0602221376631763\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 5.093997149645848e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.03883558523405716,\n    \"vf_coef\": 0.6092246418885853,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 6.825744777753561,\n    \"drawdown_penalty_weight\": 0.15576397647256385,\n    \"idle_penalty_weight\": 0.04271573174573301,\n    \"profit_bonus_weight\": 0.8270967268473195,\n    \"trade_penalty_weight\": 0.0602221376631763\n  },\n  \"experiment_tag\": \"5_base_config=None,benchmark_reward_weight=0.0000,clip_range=0.2000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=2.0000,data_key=None,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_data_normalized_h5,drawdown_penalty_weight=0.1558,ent_coef=0.0388,eval_freq=10000,exp_name=tcn_ppo_homesweep,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9500,gamma=0.9900,gpus_per_trial=0.5000,idle_penalty_weight=0.0427,initial_balance=10000.0000,learning_rate=0.0001,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=0.5000,max_steps=20000,model_type=tcn_ppo,n_epochs=5,n_eval_episodes=3,n_lstm_layers=2,n_steps=1024,norm_obs=auto,num_envs=2,num_samples=10,portfolio_change_weight=6.8257,profit_bonus_weight=0.8271,ray_address=None,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=96,shared_lstm=shared,sharpe_reward_weight=0.0000,timesteps_per_trial=500000,total_timesteps=500000,trade_penalty_weight=0.0602,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_data_normalized_h5,verbose=1,vf_coef=0.6092\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"trial_ZvH2Px_lr5.1e-05_ns1024\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_ZvH2Px_lr5.1e-05_ns1024\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745572783.898783,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {\n    \"trial_id\": \"08e4b439\"\n  },\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"e97d105a\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 7.132772379296044e-05,\n    \"gamma\": 0.995,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.05114718149629139,\n    \"vf_coef\": 0.7843023441026313,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 5.248762329596579,\n    \"drawdown_penalty_weight\": 0.14466635308093959,\n    \"idle_penalty_weight\": 0.023944961181367626,\n    \"profit_bonus_weight\": 1.2742742947266024,\n    \"trade_penalty_weight\": 0.05589908764991983\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 7.132772379296044e-05,\n    \"gamma\": 0.995,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.05114718149629139,\n    \"vf_coef\": 0.7843023441026313,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 5.248762329596579,\n    \"drawdown_penalty_weight\": 0.14466635308093959,\n    \"idle_penalty_weight\": 0.023944961181367626,\n    \"profit_bonus_weight\": 1.2742742947266024,\n    \"trade_penalty_weight\": 0.05589908764991983\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 7.132772379296044e-05,\n    \"gamma\": 0.995,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.05114718149629139,\n    \"vf_coef\": 0.7843023441026313,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 5.248762329596579,\n    \"drawdown_penalty_weight\": 0.14466635308093959,\n    \"idle_penalty_weight\": 0.023944961181367626,\n    \"profit_bonus_weight\": 1.2742742947266024,\n    \"trade_penalty_weight\": 0.05589908764991983\n  },\n  \"experiment_tag\": \"4_base_config=None,benchmark_reward_weight=0.0000,clip_range=0.2000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=2.0000,data_key=None,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_data_normalized_h5,drawdown_penalty_weight=0.1447,ent_coef=0.0511,eval_freq=10000,exp_name=tcn_ppo_homesweep,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9500,gamma=0.9950,gpus_per_trial=0.5000,idle_penalty_weight=0.0239,initial_balance=10000.0000,learning_rate=0.0001,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=1.0000,max_steps=20000,model_type=tcn_ppo,n_epochs=5,n_eval_episodes=3,n_lstm_layers=2,n_steps=4096,norm_obs=auto,num_envs=2,num_samples=10,portfolio_change_weight=5.2488,profit_bonus_weight=1.2743,ray_address=None,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=96,shared_lstm=shared,sharpe_reward_weight=0.0000,timesteps_per_trial=500000,total_timesteps=500000,trade_penalty_weight=0.0559,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_data_normalized_h5,verbose=1,vf_coef=0.7843\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"trial_3pqPDS_lr7.1e-05_ns4096\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_3pqPDS_lr7.1e-05_ns4096\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745572774.3790157,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"f55e4de6\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 5.315258002304937e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.007126036196218626,\n    \"vf_coef\": 0.5869698916239288,\n    \"clip_range\": 0.1,\n    \"gae_lambda\": 0.9,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 2.2962687218519635,\n    \"drawdown_penalty_weight\": 0.02651478762880366,\n    \"idle_penalty_weight\": 0.028851604853852422,\n    \"profit_bonus_weight\": 1.1478863897434257,\n    \"trade_penalty_weight\": 0.01480297480895706\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 5.315258002304937e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.007126036196218626,\n    \"vf_coef\": 0.5869698916239288,\n    \"clip_range\": 0.1,\n    \"gae_lambda\": 0.9,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 2.2962687218519635,\n    \"drawdown_penalty_weight\": 0.02651478762880366,\n    \"idle_penalty_weight\": 0.028851604853852422,\n    \"profit_bonus_weight\": 1.1478863897434257,\n    \"trade_penalty_weight\": 0.01480297480895706\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 5.315258002304937e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.007126036196218626,\n    \"vf_coef\": 0.5869698916239288,\n    \"clip_range\": 0.1,\n    \"gae_lambda\": 0.9,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 0.5,\n    \"portfolio_change_weight\": 2.2962687218519635,\n    \"drawdown_penalty_weight\": 0.02651478762880366,\n    \"idle_penalty_weight\": 0.028851604853852422,\n    \"profit_bonus_weight\": 1.1478863897434257,\n    \"trade_penalty_weight\": 0.01480297480895706\n  },\n  \"experiment_tag\": \"6_base_config=None,benchmark_reward_weight=0.0000,clip_range=0.1000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=2.0000,data_key=None,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_data_normalized_h5,drawdown_penalty_weight=0.0265,ent_coef=0.0071,eval_freq=10000,exp_name=tcn_ppo_homesweep,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9000,gamma=0.9900,gpus_per_trial=0.5000,idle_penalty_weight=0.0289,initial_balance=10000.0000,learning_rate=0.0001,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=0.5000,max_steps=20000,model_type=tcn_ppo,n_epochs=3,n_eval_episodes=3,n_lstm_layers=2,n_steps=1024,norm_obs=auto,num_envs=2,num_samples=10,portfolio_change_weight=2.2963,profit_bonus_weight=1.1479,ray_address=None,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=96,shared_lstm=shared,sharpe_reward_weight=0.0000,timesteps_per_trial=500000,total_timesteps=500000,trade_penalty_weight=0.0148,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_data_normalized_h5,verbose=1,vf_coef=0.5870\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"trial_Yta3vj_lr5.3e-05_ns1024\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_Yta3vj_lr5.3e-05_ns1024\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745572790.5939486,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"4fe569e1\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 0.00018402038560145096,\n    \"gamma\": 0.95,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.01286642917799782,\n    \"vf_coef\": 0.9949170857504601,\n    \"clip_range\": 0.1,\n    \"gae_lambda\": 0.9,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 2.782484567732019,\n    \"drawdown_penalty_weight\": 0.12132770669628157,\n    \"idle_penalty_weight\": 0.01698873949156749,\n    \"profit_bonus_weight\": 1.3633040893140016,\n    \"trade_penalty_weight\": 0.08651530286777158\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 0.00018402038560145096,\n    \"gamma\": 0.95,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.01286642917799782,\n    \"vf_coef\": 0.9949170857504601,\n    \"clip_range\": 0.1,\n    \"gae_lambda\": 0.9,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 2.782484567732019,\n    \"drawdown_penalty_weight\": 0.12132770669628157,\n    \"idle_penalty_weight\": 0.01698873949156749,\n    \"profit_bonus_weight\": 1.3633040893140016,\n    \"trade_penalty_weight\": 0.08651530286777158\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00018402038560145096,\n    \"gamma\": 0.95,\n    \"n_steps\": 4096,\n    \"ent_coef\": 0.01286642917799782,\n    \"vf_coef\": 0.9949170857504601,\n    \"clip_range\": 0.1,\n    \"gae_lambda\": 0.9,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 2.782484567732019,\n    \"drawdown_penalty_weight\": 0.12132770669628157,\n    \"idle_penalty_weight\": 0.01698873949156749,\n    \"profit_bonus_weight\": 1.3633040893140016,\n    \"trade_penalty_weight\": 0.08651530286777158\n  },\n  \"experiment_tag\": \"7_base_config=None,benchmark_reward_weight=0.0000,clip_range=0.1000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=2.0000,data_key=None,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_data_normalized_h5,drawdown_penalty_weight=0.1213,ent_coef=0.0129,eval_freq=10000,exp_name=tcn_ppo_homesweep,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9000,gamma=0.9500,gpus_per_trial=0.5000,idle_penalty_weight=0.0170,initial_balance=10000.0000,learning_rate=0.0002,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=1.0000,max_steps=20000,model_type=tcn_ppo,n_epochs=3,n_eval_episodes=3,n_lstm_layers=2,n_steps=4096,norm_obs=auto,num_envs=2,num_samples=10,portfolio_change_weight=2.7825,profit_bonus_weight=1.3633,ray_address=None,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=96,shared_lstm=shared,sharpe_reward_weight=0.0000,timesteps_per_trial=500000,total_timesteps=500000,trade_penalty_weight=0.0865,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_data_normalized_h5,verbose=1,vf_coef=0.9949\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"trial_k4dxSS_lr1.8e-04_ns4096\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_k4dxSS_lr1.8e-04_ns4096\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745572799.8332293,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"458c01b4\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595df030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c1174636e5f70706f5f686f6d657377656570948c0e747269616c5f6469725f6e616d65948c1d747269616c5f424e375363675f6c72312e34652d30345f6e7332303438948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1446696c6553797374656d2e5f66726f6d5f7572699493948c0966696c653a2f2f2f5f94859452948c0f73746f726167655f66735f70617468948c2a433a2f55736572732f757365722f4465736b746f702f6c74736d2d64716e2f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819681f68114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d649468008c125f75706c6f61645f746f5f66735f706174689493947d94288c0a6c6f63616c5f70617468948c8e433a2f55736572732f757365722f417070446174612f4c6f63616c2f54656d702f7261792f73657373696f6e5f323032352d30342d32355f31312d31392d30325f3035303133325f32313931362f6172746966616374732f323032352d30342d32355f31312d31392d30342f74636e5f70706f5f686f6d6573776565702f6472697665725f617274696661637473948c02667394681f8c0766735f70617468948c3c433a2f55736572732f757365722f4465736b746f702f6c74736d2d64716e2f7261795f726573756c74732f74636e5f70706f5f686f6d657377656570948c076578636c756465944e75869475628c0a5f74696d657374616d70948c13323032352d30342d32355f31312d31392d30349475622e\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 0.00013704290000718863,\n    \"gamma\": 0.95,\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.011579884408972755,\n    \"vf_coef\": 0.6652975734678237,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.98,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 4.615071169200363,\n    \"drawdown_penalty_weight\": 0.049764029164275796,\n    \"idle_penalty_weight\": 0.008415987722226343,\n    \"profit_bonus_weight\": 0.9093832992474682,\n    \"trade_penalty_weight\": 0.04386383160786035\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 0.00013704290000718863,\n    \"gamma\": 0.95,\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.011579884408972755,\n    \"vf_coef\": 0.6652975734678237,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.98,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 4.615071169200363,\n    \"drawdown_penalty_weight\": 0.049764029164275796,\n    \"idle_penalty_weight\": 0.008415987722226343,\n    \"profit_bonus_weight\": 0.9093832992474682,\n    \"trade_penalty_weight\": 0.04386383160786035\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00013704290000718863,\n    \"gamma\": 0.95,\n    \"n_steps\": 2048,\n    \"ent_coef\": 0.011579884408972755,\n    \"vf_coef\": 0.6652975734678237,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.98,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 4.615071169200363,\n    \"drawdown_penalty_weight\": 0.049764029164275796,\n    \"idle_penalty_weight\": 0.008415987722226343,\n    \"profit_bonus_weight\": 0.9093832992474682,\n    \"trade_penalty_weight\": 0.04386383160786035\n  },\n  \"experiment_tag\": \"8_base_config=None,benchmark_reward_weight=0.0000,clip_range=0.2000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=2.0000,data_key=None,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_data_normalized_h5,drawdown_penalty_weight=0.0498,ent_coef=0.0116,eval_freq=10000,exp_name=tcn_ppo_homesweep,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9800,gamma=0.9500,gpus_per_trial=0.5000,idle_penalty_weight=0.0084,initial_balance=10000.0000,learning_rate=0.0001,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=1.0000,max_steps=20000,model_type=tcn_ppo,n_epochs=5,n_eval_episodes=3,n_lstm_layers=2,n_steps=2048,norm_obs=auto,num_envs=2,num_samples=10,portfolio_change_weight=4.6151,profit_bonus_weight=0.9094,ray_address=None,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=96,shared_lstm=shared,sharpe_reward_weight=0.0000,timesteps_per_trial=500000,total_timesteps=500000,trade_penalty_weight=0.0439,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_data_normalized_h5,verbose=1,vf_coef=0.6653\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"trial_BN7Scg_lr1.4e-04_ns2048\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_BN7Scg_lr1.4e-04_ns2048\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745572806.503917,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {\n    \"trial_id\": \"458c01b4\"\n  },\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"d64b3d26\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 0.00013169903339622878,\n    \"gamma\": 0.95,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.06437214721181102,\n    \"vf_coef\": 0.7288020499753937,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.98,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 6.485333185836812,\n    \"drawdown_penalty_weight\": 0.04676323644368764,\n    \"idle_penalty_weight\": 0.0037510789834989677,\n    \"profit_bonus_weight\": 1.123756161885872,\n    \"trade_penalty_weight\": 0.029513554576440604\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 0.00013169903339622878,\n    \"gamma\": 0.95,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.06437214721181102,\n    \"vf_coef\": 0.7288020499753937,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.98,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 6.485333185836812,\n    \"drawdown_penalty_weight\": 0.04676323644368764,\n    \"idle_penalty_weight\": 0.0037510789834989677,\n    \"profit_bonus_weight\": 1.123756161885872,\n    \"trade_penalty_weight\": 0.029513554576440604\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 0.00013169903339622878,\n    \"gamma\": 0.95,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.06437214721181102,\n    \"vf_coef\": 0.7288020499753937,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.98,\n    \"n_epochs\": 3,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 6.485333185836812,\n    \"drawdown_penalty_weight\": 0.04676323644368764,\n    \"idle_penalty_weight\": 0.0037510789834989677,\n    \"profit_bonus_weight\": 1.123756161885872,\n    \"trade_penalty_weight\": 0.029513554576440604\n  },\n  \"experiment_tag\": \"9_base_config=None,benchmark_reward_weight=0.0000,clip_range=0.2000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=2.0000,data_key=None,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_data_normalized_h5,drawdown_penalty_weight=0.0468,ent_coef=0.0644,eval_freq=10000,exp_name=tcn_ppo_homesweep,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9800,gamma=0.9500,gpus_per_trial=0.5000,idle_penalty_weight=0.0038,initial_balance=10000.0000,learning_rate=0.0001,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=1.0000,max_steps=20000,model_type=tcn_ppo,n_epochs=3,n_eval_episodes=3,n_lstm_layers=2,n_steps=1024,norm_obs=auto,num_envs=2,num_samples=10,portfolio_change_weight=6.4853,profit_bonus_weight=1.1238,ray_address=None,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=96,shared_lstm=shared,sharpe_reward_weight=0.0000,timesteps_per_trial=500000,total_timesteps=500000,trade_penalty_weight=0.0295,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_data_normalized_h5,verbose=1,vf_coef=0.7288\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"trial_QVZxTJ_lr1.3e-04_ns1024\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_QVZxTJ_lr1.3e-04_ns1024\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745572815.8677118,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"train_rl_agent_tune\",\n  \"trial_id\": \"d08d9670\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 9.857646567314452e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.051179580111402466,\n    \"vf_coef\": 0.5169434464584971,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 6.457829969131328,\n    \"drawdown_penalty_weight\": 0.13172560864036104,\n    \"idle_penalty_weight\": 0.00672999443098481,\n    \"profit_bonus_weight\": 1.1417030813321298,\n    \"trade_penalty_weight\": 0.024838135330605284\n  },\n  \"_Trial__unresolved_config\": {\n    \"model_type\": \"tcn_ppo\",\n    \"features\": \"open_scaled,high_scaled,low_scaled,close_scaled,volume_scaled,sma_7_scaled,sma_25_scaled,sma_99_scaled,ema_9_scaled,ema_21_scaled,rsi_14_scaled,open_scaled_4h,high_scaled_4h,low_scaled_4h,close_scaled_4h,volume_scaled_4h,sma_7_scaled_4h,sma_25_scaled_4h,sma_99_scaled_4h,ema_9_scaled_4h,ema_21_scaled_4h,rsi_14_scaled_4h,open_scaled_1d,high_scaled_1d,low_scaled_1d,close_scaled_1d,volume_scaled_1d,sma_7_scaled_1d,sma_25_scaled_1d,sma_99_scaled_1d,ema_9_scaled_1d,ema_21_scaled_1d,rsi_14_scaled_1d\",\n    \"sharpe_reward_weight\": 0.0,\n    \"fee_penalty_weight\": 0.0,\n    \"benchmark_reward_weight\": 0.0,\n    \"consistency_penalty_weight\": 0.0,\n    \"exploration_bonus_weight\": 0.0,\n    \"lstm_hidden_size\": 256,\n    \"n_lstm_layers\": 2,\n    \"shared_lstm\": \"shared\",\n    \"sequence_length\": 96,\n    \"max_steps\": 20000,\n    \"initial_balance\": 10000.0,\n    \"commission\": 0.0,\n    \"reward_scaling\": 1.0,\n    \"norm_obs\": \"auto\",\n    \"total_timesteps\": 500000,\n    \"eval_freq\": 10000,\n    \"n_eval_episodes\": 3,\n    \"save_freq\": 50000,\n    \"verbose\": 1,\n    \"data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\train_data_normalized.h5\",\n    \"val_data_path\": \"C:\\\\Users\\\\user\\\\Desktop\\\\ltsm-dqn\\\\data\\\\historic_norm\\\\val_data_normalized.h5\",\n    \"data_key\": null,\n    \"exp_name\": \"tcn_ppo_homesweep\",\n    \"num_samples\": 10,\n    \"cpus_per_trial\": 2.0,\n    \"gpus_per_trial\": 0.5,\n    \"search_algo\": \"optuna\",\n    \"local_dir\": \"./ray_results\",\n    \"timesteps_per_trial\": 500000,\n    \"ray_address\": null,\n    \"base_config\": null,\n    \"cpu_only\": false,\n    \"num_envs\": 2,\n    \"learning_rate\": 9.857646567314452e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.051179580111402466,\n    \"vf_coef\": 0.5169434464584971,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 6.457829969131328,\n    \"drawdown_penalty_weight\": 0.13172560864036104,\n    \"idle_penalty_weight\": 0.00672999443098481,\n    \"profit_bonus_weight\": 1.1417030813321298,\n    \"trade_penalty_weight\": 0.024838135330605284\n  },\n  \"evaluated_params\": {\n    \"learning_rate\": 9.857646567314452e-05,\n    \"gamma\": 0.99,\n    \"n_steps\": 1024,\n    \"ent_coef\": 0.051179580111402466,\n    \"vf_coef\": 0.5169434464584971,\n    \"clip_range\": 0.2,\n    \"gae_lambda\": 0.95,\n    \"n_epochs\": 5,\n    \"max_grad_norm\": 1.0,\n    \"portfolio_change_weight\": 6.457829969131328,\n    \"drawdown_penalty_weight\": 0.13172560864036104,\n    \"idle_penalty_weight\": 0.00672999443098481,\n    \"profit_bonus_weight\": 1.1417030813321298,\n    \"trade_penalty_weight\": 0.024838135330605284\n  },\n  \"experiment_tag\": \"10_base_config=None,benchmark_reward_weight=0.0000,clip_range=0.2000,commission=0.0000,consistency_penalty_weight=0.0000,cpu_only=False,cpus_per_trial=2.0000,data_key=None,data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_train_data_normalized_h5,drawdown_penalty_weight=0.1317,ent_coef=0.0512,eval_freq=10000,exp_name=tcn_ppo_homesweep,exploration_bonus_weight=0.0000,features=open_scaled_high_scaled_low_scaled_close_scaled_volume_scaled_sma_7_scaled_sma_25_scaled_sma_99_scaled_ema_9_scaled_ema_21_scaled_rsi_14_scaled_open_scaled_4h_high_scaled_4h_low_scaled_4h_close_scaled_4h_volume_scaled_4h_sma_7_scaled_4h_sma_25_scaled_4h_sma_99_scaled_4h_ema_9_scaled_4h_ema_21_scaled_4h_rsi_14_scaled_4h_open_scaled_1d_high_scaled_1d_low_scaled_1d_close_scaled_1d_volume_scaled_1d_sma_7_scaled_1d_sma_25_scaled_1d_sma_99_scaled_1d_ema_9_scaled_1d_ema_21_scaled_1d_rsi_14_scaled_1d,fee_penalty_weight=0.0000,gae_lambda=0.9500,gamma=0.9900,gpus_per_trial=0.5000,idle_penalty_weight=0.0067,initial_balance=10000.0000,learning_rate=0.0001,local_dir=ray_results,lstm_hidden_size=256,max_grad_norm=1.0000,max_steps=20000,model_type=tcn_ppo,n_epochs=5,n_eval_episodes=3,n_lstm_layers=2,n_steps=1024,norm_obs=auto,num_envs=2,num_samples=10,portfolio_change_weight=6.4578,profit_bonus_weight=1.1417,ray_address=None,reward_scaling=1.0000,save_freq=50000,search_algo=optuna,sequence_length=96,shared_lstm=shared,sharpe_reward_weight=0.0000,timesteps_per_trial=500000,total_timesteps=500000,trade_penalty_weight=0.0248,val_data_path=C_Users_user_Desktop_ltsm-dqn_data_historic_norm_val_data_normalized_h5,verbose=1,vf_coef=0.5169\",\n  \"stopping_criterion\": {},\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c03435055944740000000000000008c0347505594473fe000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"trial_9f9cUK_lr9.9e-05_ns1024\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059540000000000000008c1c726c5f6167656e742e74756e652e72756e5f74756e655f7377656570948c1b73686f72745f747269616c5f6469726e616d655f63726561746f729493942e\"\n  },\n  \"custom_trial_name\": null,\n  \"custom_dirname\": \"trial_9f9cUK_lr9.9e-05_ns1024\",\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1745572822.5058837,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {},\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059585010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": 78895.578, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 1, "_metric": null, "_total_time": 0, "_iteration": 875, "_has_errored": true, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1745572744.8652163, "_session_str": "2025-04-25_11-19-04", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f3000000000000008c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944b028c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1745572744.8652163}}